{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - Text Classification - Multinomial & Bernoulli\n",
    "\n",
    "In this notebook you will apply the Naive Bayes algorithms for text classification.\n",
    "\n",
    "Your tasks are marked with task numbers (e.g., Task 1). To get full credit you need to complete **ALL** tasks.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset: The 20 Newsgroups data set\n",
    "\n",
    "\n",
    "The 20 newsgroups dataset comprises around 20,000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering. The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "Following is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "- alt.atheism\n",
    "- comp.graphics\n",
    "- comp.os.ms-windows.misc\n",
    "- comp.sys.ibm.pc.hardware\n",
    "- comp.sys.mac.hardware\n",
    "- comp.windows.x\n",
    "- misc.forsale\n",
    "- rec.autos\n",
    "- rec.motorcycles\n",
    "- rec.sport.baseball\n",
    "- rec.sport.hockey\n",
    "- sci.crypt\n",
    "- sci.electronics\n",
    "- sci.med\n",
    "- sci.space\n",
    "- soc.religion.christian\n",
    "- talk.politics.guns\n",
    "- talk.politics.mideast\n",
    "- talk.politics.misc\n",
    "- talk.religion.misc\n",
    "\n",
    "\n",
    "You will normalize the documents, perform preprocessing and vectorize the features. Since the features are categorical, you will implement two different naive Bayes classifiers using Scikit-Learn. \n",
    "- Categorical features (binary valued) are modeled using the Multivariate Bernoulli distrubition \n",
    "- Categorical features (multi-valued) are modeled using the Multinomial distrubition \n",
    "\n",
    "\n",
    "## Steps for Classification:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Feature Extraction\n",
    "   - a. Text Normalization (Stemming & Lemmatization)\n",
    "   - b. Text Preprocessing (Tokenization, removing stop words, etc.)\n",
    "   - c. Vectorization of the features\n",
    "3. Model Selection by Hyperparameter Tuning\n",
    "4. Train the Optimal Model\n",
    "5. Analyzing Model Performance\n",
    "6. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/smaan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer , PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "You will work on a partial dataset with only 4 categories out of the 20 available in the dataset:\n",
    "- alt.atheism\n",
    "- soc.religion.christian\n",
    "- comp.graphics\n",
    "- sci.med\n",
    "\n",
    "\n",
    "The samples are shuffled randomly. This is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "X_train = train_data.data\n",
    "y_train = train_data.target\n",
    "\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 1. Exploratory Data Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "\n",
      "Number of Training Examples:  2257\n",
      "Number of Training Labels:  2257\n",
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n",
      "\n",
      "Print a Random Document:\n",
      "\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "[1 1 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Names: \", train_data.target_names)\n",
    "\n",
    "print(\"\\nNumber of Training Examples: \", len(X_train))\n",
    "print(\"Number of Training Labels: \", len(y_train))\n",
    "\n",
    "print(\"Number of Test Examples: \",len(X_test))\n",
    "print(\"Number of Test Labels: \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"\\nPrint a Random Document:\\n\")\n",
    "print(X_train[0])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "#### Task 1: Compute class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2257 entries, 0 to 2256\n",
      "Data columns (total 1 columns):\n",
      "0    2257 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 17.7 KB\n",
      "3    599\n",
      "2    594\n",
      "1    584\n",
      "0    480\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train)\n",
    "df.describe()\n",
    "df.info()\n",
    "\n",
    "\n",
    "label_counts = df.iloc[:,-1].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Class Distribution\n",
    "\n",
    "\n",
    "#### Task 2: Generate visualization of the class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df.iloc[:,-1].value_counts()\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.barplot(label_counts.index, label_counts.values, alpha = 0.9)\n",
    "\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('Spam', fontsize =12)\n",
    "plt.ylabel('Counts', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## a) Text Normalization by Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.\n",
    "\n",
    "\n",
    "#### Task 3: Lemmatize the training data. You may stem it as well, if it improves the classification accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                    text\n",
      "0     From: sd345@city.ac.uk (Michael Collier)\\nSubj...\n",
      "1     From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...\n",
      "2     From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...\n",
      "3     From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...\n",
      "4     From: stanly@grok11.columbiasc.ncr.com (stanly...\n",
      "5     From: vbv@lor.eeap.cwru.edu (Virgilio (Dean) B...\n",
      "6     From: jodfishe@silver.ucs.indiana.edu (joseph ...\n",
      "7     From: aldridge@netcom.com (Jacquelin Aldridge)...\n",
      "8     From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
      "9     From: libman@hsc.usc.edu (Marlena Libman)\\nSub...\n",
      "10    From: anasaz!karl@anasazi.com (Karl Dussik)\\nS...\n",
      "11    From: amjad@eng.umd.edu (Amjad A Soomro)\\nSubj...\n",
      "12    From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...\n",
      "13    Subject: So what is Maddi?\\nFrom: madhaus@netc...\n",
      "14    From: sloan@cis.uab.edu (Kenneth Sloan)\\nSubje...\n",
      "15    From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...\n",
      "16    From: texx@ossi.com (Robert \"Texx\" Woodworth)\\...\n",
      "17    Organization: Penn State University\\nFrom: <JS...\n",
      "18    From: tom_milligan@rainbow.mentorg.com\\nSubjec...\n",
      "19    Subject: Re: Don't more innocents die without ...\n",
      "20    From: dotsonm@dmapub.dma.org (Mark Dotson)\\nSu...\n",
      "21    From: gmiller@worldbank.org (Gene C. Miller)\\n...\n",
      "22    From: jkellett@netcom.com (Joe Kellett)\\nSubje...\n",
      "23    From: d91-hes@tekn.hj.se (STEFAN HERMANSSON)\\n...\n",
      "24    From: mjw19@cl.cam.ac.uk (M.J. Williams)\\nSubj...\n",
      "25    From: dstampe@psych.toronto.edu (Dave Stampe)\\...\n",
      "26    From: christian@geneva.rutgers.edu\\nSubject: e...\n",
      "27    From: ruthless@panix.com (Ruth Ditucci)\\nSubje...\n",
      "28    From: rind@enterprise.bih.harvard.edu (David R...\n",
      "29    From: spp@zabriskie.berkeley.edu (Steve Pope)\\...\n",
      "...                                                 ...\n",
      "2227  From: halat@pooh.bears (Jim Halat)\\nSubject: R...\n",
      "2228  From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...\n",
      "2229  From: jcj@tellabs.com (jcj)\\nSubject: Re: proo...\n",
      "2230  From: news@cbnewsk.att.com\\nSubject: Re: Bible...\n",
      "2231  Subject: Re: Feminism and Islam, again\\nFrom: ...\n",
      "2232  From: lipman@oasys.dt.navy.mil (Robert Lipman)...\n",
      "2233  From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...\n",
      "2234  From: David.Rice@ofa123.fidonet.org\\nSubject: ...\n",
      "2235  From: dougb@comm.mot.com (Doug Bank)\\nSubject:...\n",
      "2236  From: dkusswur@falcon.depaul.edu (Daniel C. Ku...\n",
      "2237  From: datepper@phoenix.Princeton.EDU (David Aa...\n",
      "2238  From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
      "2239  From: paj@uk.co.gec-mrc (Paul Johnson)\\nSubjec...\n",
      "2240  From: balick@nynexst.com (Daphne Balick)\\nSubj...\n",
      "2241  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...\n",
      "2242  From: Sean McMains <mcmains@unt.edu>\\nSubject:...\n",
      "2243  From: turpin@cs.utexas.edu (Russell Turpin)\\nS...\n",
      "2244  From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
      "2245  From: nyeda@cnsvax.uwec.edu (David Nye)\\nSubje...\n",
      "2246  From: lmvec@westminster.ac.uk (William Hargrea...\n",
      "2247  From: daniels@math.ufl.edu (TV's Big Dealer)\\n...\n",
      "2248  From: \"danny hawrysio\" <danny.hawrysio@canrem....\n",
      "2249  From: shellgate!llo@uu4.psi.com (Larry L. Over...\n",
      "2250  From: ingles@engin.umich.edu (Ray Ingles)\\nSub...\n",
      "2251  From: Mark-Tarbell@suite.com\\nSubject: Amnioce...\n",
      "2252  From: roos@Operoni.Helsinki.FI (Christophe Roo...\n",
      "2253  From: mhollowa@ic.sunysb.edu (Michael Holloway...\n",
      "2254  From: sasghm@theseus.unx.sas.com (Gary Merrill...\n",
      "2255  From: Dan Wallach <dwallach@cs.berkeley.edu>\\n...\n",
      "2256  From: dyer@spdcc.com (Steve Dyer)\\nSubject: Re...\n",
      "\n",
      "[2257 rows x 1 columns]>\n",
      "<bound method DataFrame.info of                                                    text\n",
      "0     From: brian@ucsd.edu (Brian Kantor)\\nSubject: ...\n",
      "1     From: rind@enterprise.bih.harvard.edu (David R...\n",
      "2     From: adwright@iastate.edu ()\\nSubject: Re: ce...\n",
      "3     From: livesey@solntze.wpd.sgi.com (Jon Livesey...\n",
      "4     From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...\n",
      "5     From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...\n",
      "6     From: kintur@scorch.apana.org.au (Kingsley Tur...\n",
      "7     From: hudson@athena.cs.uga.edu (Paul Hudson Jr...\n",
      "8     From: GWGREG01@ukcc.uky.edu\\nSubject: Re: Preg...\n",
      "9     From: stanley@skyking.OCE.ORST.EDU (John Stanl...\n",
      "10    From: raunoh@otol.fi (Rauno Haapaniemi)\\nSubje...\n",
      "11    From: JEK@cu.nih.gov\\nSubject: Mary, \"blessed ...\n",
      "12    From: \"Gabriel D. Underwood\" <gabe+@CMU.EDU>\\n...\n",
      "13    From: gchin@ssf.Eng.Sun.COM (Gary Chin)\\nSubje...\n",
      "14    From: sigma@rahul.net (Kevin Martin)\\nSubject:...\n",
      "15    From: swf@elsegundoca.ncr.com (Stan Friesen)\\n...\n",
      "16    From: graeme@labtam.labtam.oz.au (Graeme Gill)...\n",
      "17    From: sfp@lemur.cit.cornell.edu (Sheila Patter...\n",
      "18    From: decay@cbnewsj.cb.att.com (dean.kaflowitz...\n",
      "19    From: mathew <mathew@mantis.co.uk>\\nSubject: D...\n",
      "20    From: vrao@nyx.cs.du.edu (Vinay Rao)\\nSubject:...\n",
      "21    From: Rick_Granberry@pts.mot.com (Rick Granber...\n",
      "22    From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...\n",
      "23    From: danb@shell.portal.com (Dan E Babcock)\\nS...\n",
      "24    From: stephen@mont.cs.missouri.edu (Stephen Mo...\n",
      "25    From: broehl@sunee.uwaterloo.ca (Bernie Roehl)...\n",
      "26    From: UC512052@mizzou1.missouri.edu (David K. ...\n",
      "27    From: Eugene.Bigelow@ebay.sun.com (Geno )\\nSub...\n",
      "28    From: turpin@cs.utexas.edu (Russell Turpin)\\nS...\n",
      "29    From: pww@spacsun.rice.edu (Peter Walker)\\nSub...\n",
      "...                                                 ...\n",
      "1472  From: wes@uf.msc.edu (Wes Barris)\\nSubject: Re...\n",
      "1473  From: deniaud@cartoon.inria.fr (Gilles Deniaud...\n",
      "1474  From: koberg@spot.Colorado.EDU (Allen Koberg)\\...\n",
      "1475  From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...\n",
      "1476  From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...\n",
      "1477  From: REXLEX@fnal.fnal.gov\\nSubject: Re: Homos...\n",
      "1478  From: deb47099@uxa.cso.uiuc.edu (Daniel E. Bra...\n",
      "1479  From: giamomj@duvm.ocs.drexel.edu (Mike G.)\\nS...\n",
      "1480  From: wilsonr@logica.co.uk\\nSubject: Re: What ...\n",
      "1481  From: picl25@fsphy1.physics.fsu.edu (PICL acco...\n",
      "1482  From: iharkest@Lise.Unit.NO (Inge Harkestad)\\n...\n",
      "1483  From: mac@utkvx.bitnet (Richard J. McDougald)\\...\n",
      "1484  From: picl25@fsphy1.physics.fsu.edu (PICL acco...\n",
      "1485  From: prevost@eos.arc.nasa.gov (Michael Prevos...\n",
      "1486  From: eric@ithaca.com (Eric Wagner)\\nSubject: ...\n",
      "1487  From: kiran@village.com (Kiran Wagle)\\nSubject...\n",
      "1488  From: pat@nick.csh.rit.edu (Pat Fleckenstein (...\n",
      "1489  From: aaron@minster.york.ac.uk\\nSubject: Re: D...\n",
      "1490  From: sun075!Gerry.Palo@uunet.uu.net (Gerry Pa...\n",
      "1491  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...\n",
      "1492  From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...\n",
      "1493  From: rak@crosfield.co.uk (Richard Kirk)\\nSubj...\n",
      "1494  From: mcovingt@aisun3.ai.uga.edu (Michael Covi...\n",
      "1495  From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...\n",
      "1496  From: ac940@Freenet.carleton.ca (Lau Hon-Wah)\\...\n",
      "1497  From: andersom@spot.Colorado.EDU (Marc Anderso...\n",
      "1498  From: bj368@cleveland.Freenet.Edu (Mike E. Rom...\n",
      "1499  From: Donald Mackie <Donald_Mackie@med.umich.e...\n",
      "1500  From: abruno@adobe (Andrea Bruno)\\nSubject: Re...\n",
      "1501  From: matt-dah@dsv.su.se (Mattias Dahlberg)\\nS...\n",
      "\n",
      "[1502 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(X_train)):\n",
    "    X_train[x] = (X_train[x],)\n",
    "\n",
    "df_lem_train = pd.DataFrame.from_records(X_train, columns = ['text'])\n",
    "print(df_lem_train.info)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "X_lem_train = df_lem_train['text'].map(lambda text: lemmatizer.lemmatize(text))\n",
    "\n",
    "\n",
    "for x in range(len(X_test)):\n",
    "    X_test[x] = (X_test[x],)\n",
    "\n",
    "df_lem_test = pd.DataFrame.from_records(X_test, columns = ['text'])\n",
    "print(df_lem_test.info)\n",
    "X_lem_test = df_lem_test['text'].map(lambda text: lemmatizer.lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                    text\n",
      "0     From: sd345@city.ac.uk (Michael Collier)\\nSubj...\n",
      "1     From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...\n",
      "2     From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...\n",
      "3     From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...\n",
      "4     From: stanly@grok11.columbiasc.ncr.com (stanly...\n",
      "5     From: vbv@lor.eeap.cwru.edu (Virgilio (Dean) B...\n",
      "6     From: jodfishe@silver.ucs.indiana.edu (joseph ...\n",
      "7     From: aldridge@netcom.com (Jacquelin Aldridge)...\n",
      "8     From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
      "9     From: libman@hsc.usc.edu (Marlena Libman)\\nSub...\n",
      "10    From: anasaz!karl@anasazi.com (Karl Dussik)\\nS...\n",
      "11    From: amjad@eng.umd.edu (Amjad A Soomro)\\nSubj...\n",
      "12    From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...\n",
      "13    Subject: So what is Maddi?\\nFrom: madhaus@netc...\n",
      "14    From: sloan@cis.uab.edu (Kenneth Sloan)\\nSubje...\n",
      "15    From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...\n",
      "16    From: texx@ossi.com (Robert \"Texx\" Woodworth)\\...\n",
      "17    Organization: Penn State University\\nFrom: <JS...\n",
      "18    From: tom_milligan@rainbow.mentorg.com\\nSubjec...\n",
      "19    Subject: Re: Don't more innocents die without ...\n",
      "20    From: dotsonm@dmapub.dma.org (Mark Dotson)\\nSu...\n",
      "21    From: gmiller@worldbank.org (Gene C. Miller)\\n...\n",
      "22    From: jkellett@netcom.com (Joe Kellett)\\nSubje...\n",
      "23    From: d91-hes@tekn.hj.se (STEFAN HERMANSSON)\\n...\n",
      "24    From: mjw19@cl.cam.ac.uk (M.J. Williams)\\nSubj...\n",
      "25    From: dstampe@psych.toronto.edu (Dave Stampe)\\...\n",
      "26    From: christian@geneva.rutgers.edu\\nSubject: e...\n",
      "27    From: ruthless@panix.com (Ruth Ditucci)\\nSubje...\n",
      "28    From: rind@enterprise.bih.harvard.edu (David R...\n",
      "29    From: spp@zabriskie.berkeley.edu (Steve Pope)\\...\n",
      "...                                                 ...\n",
      "2227  From: halat@pooh.bears (Jim Halat)\\nSubject: R...\n",
      "2228  From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...\n",
      "2229  From: jcj@tellabs.com (jcj)\\nSubject: Re: proo...\n",
      "2230  From: news@cbnewsk.att.com\\nSubject: Re: Bible...\n",
      "2231  Subject: Re: Feminism and Islam, again\\nFrom: ...\n",
      "2232  From: lipman@oasys.dt.navy.mil (Robert Lipman)...\n",
      "2233  From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...\n",
      "2234  From: David.Rice@ofa123.fidonet.org\\nSubject: ...\n",
      "2235  From: dougb@comm.mot.com (Doug Bank)\\nSubject:...\n",
      "2236  From: dkusswur@falcon.depaul.edu (Daniel C. Ku...\n",
      "2237  From: datepper@phoenix.Princeton.EDU (David Aa...\n",
      "2238  From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
      "2239  From: paj@uk.co.gec-mrc (Paul Johnson)\\nSubjec...\n",
      "2240  From: balick@nynexst.com (Daphne Balick)\\nSubj...\n",
      "2241  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...\n",
      "2242  From: Sean McMains <mcmains@unt.edu>\\nSubject:...\n",
      "2243  From: turpin@cs.utexas.edu (Russell Turpin)\\nS...\n",
      "2244  From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
      "2245  From: nyeda@cnsvax.uwec.edu (David Nye)\\nSubje...\n",
      "2246  From: lmvec@westminster.ac.uk (William Hargrea...\n",
      "2247  From: daniels@math.ufl.edu (TV's Big Dealer)\\n...\n",
      "2248  From: \"danny hawrysio\" <danny.hawrysio@canrem....\n",
      "2249  From: shellgate!llo@uu4.psi.com (Larry L. Over...\n",
      "2250  From: ingles@engin.umich.edu (Ray Ingles)\\nSub...\n",
      "2251  From: Mark-Tarbell@suite.com\\nSubject: Amnioce...\n",
      "2252  From: roos@Operoni.Helsinki.FI (Christophe Roo...\n",
      "2253  From: mhollowa@ic.sunysb.edu (Michael Holloway...\n",
      "2254  From: sasghm@theseus.unx.sas.com (Gary Merrill...\n",
      "2255  From: Dan Wallach <dwallach@cs.berkeley.edu>\\n...\n",
      "2256  From: dyer@spdcc.com (Steve Dyer)\\nSubject: Re...\n",
      "\n",
      "[2257 rows x 1 columns]>\n",
      "<bound method DataFrame.info of                                                    text\n",
      "0     From: brian@ucsd.edu (Brian Kantor)\\nSubject: ...\n",
      "1     From: rind@enterprise.bih.harvard.edu (David R...\n",
      "2     From: adwright@iastate.edu ()\\nSubject: Re: ce...\n",
      "3     From: livesey@solntze.wpd.sgi.com (Jon Livesey...\n",
      "4     From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...\n",
      "5     From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...\n",
      "6     From: kintur@scorch.apana.org.au (Kingsley Tur...\n",
      "7     From: hudson@athena.cs.uga.edu (Paul Hudson Jr...\n",
      "8     From: GWGREG01@ukcc.uky.edu\\nSubject: Re: Preg...\n",
      "9     From: stanley@skyking.OCE.ORST.EDU (John Stanl...\n",
      "10    From: raunoh@otol.fi (Rauno Haapaniemi)\\nSubje...\n",
      "11    From: JEK@cu.nih.gov\\nSubject: Mary, \"blessed ...\n",
      "12    From: \"Gabriel D. Underwood\" <gabe+@CMU.EDU>\\n...\n",
      "13    From: gchin@ssf.Eng.Sun.COM (Gary Chin)\\nSubje...\n",
      "14    From: sigma@rahul.net (Kevin Martin)\\nSubject:...\n",
      "15    From: swf@elsegundoca.ncr.com (Stan Friesen)\\n...\n",
      "16    From: graeme@labtam.labtam.oz.au (Graeme Gill)...\n",
      "17    From: sfp@lemur.cit.cornell.edu (Sheila Patter...\n",
      "18    From: decay@cbnewsj.cb.att.com (dean.kaflowitz...\n",
      "19    From: mathew <mathew@mantis.co.uk>\\nSubject: D...\n",
      "20    From: vrao@nyx.cs.du.edu (Vinay Rao)\\nSubject:...\n",
      "21    From: Rick_Granberry@pts.mot.com (Rick Granber...\n",
      "22    From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...\n",
      "23    From: danb@shell.portal.com (Dan E Babcock)\\nS...\n",
      "24    From: stephen@mont.cs.missouri.edu (Stephen Mo...\n",
      "25    From: broehl@sunee.uwaterloo.ca (Bernie Roehl)...\n",
      "26    From: UC512052@mizzou1.missouri.edu (David K. ...\n",
      "27    From: Eugene.Bigelow@ebay.sun.com (Geno )\\nSub...\n",
      "28    From: turpin@cs.utexas.edu (Russell Turpin)\\nS...\n",
      "29    From: pww@spacsun.rice.edu (Peter Walker)\\nSub...\n",
      "...                                                 ...\n",
      "1472  From: wes@uf.msc.edu (Wes Barris)\\nSubject: Re...\n",
      "1473  From: deniaud@cartoon.inria.fr (Gilles Deniaud...\n",
      "1474  From: koberg@spot.Colorado.EDU (Allen Koberg)\\...\n",
      "1475  From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...\n",
      "1476  From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...\n",
      "1477  From: REXLEX@fnal.fnal.gov\\nSubject: Re: Homos...\n",
      "1478  From: deb47099@uxa.cso.uiuc.edu (Daniel E. Bra...\n",
      "1479  From: giamomj@duvm.ocs.drexel.edu (Mike G.)\\nS...\n",
      "1480  From: wilsonr@logica.co.uk\\nSubject: Re: What ...\n",
      "1481  From: picl25@fsphy1.physics.fsu.edu (PICL acco...\n",
      "1482  From: iharkest@Lise.Unit.NO (Inge Harkestad)\\n...\n",
      "1483  From: mac@utkvx.bitnet (Richard J. McDougald)\\...\n",
      "1484  From: picl25@fsphy1.physics.fsu.edu (PICL acco...\n",
      "1485  From: prevost@eos.arc.nasa.gov (Michael Prevos...\n",
      "1486  From: eric@ithaca.com (Eric Wagner)\\nSubject: ...\n",
      "1487  From: kiran@village.com (Kiran Wagle)\\nSubject...\n",
      "1488  From: pat@nick.csh.rit.edu (Pat Fleckenstein (...\n",
      "1489  From: aaron@minster.york.ac.uk\\nSubject: Re: D...\n",
      "1490  From: sun075!Gerry.Palo@uunet.uu.net (Gerry Pa...\n",
      "1491  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...\n",
      "1492  From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...\n",
      "1493  From: rak@crosfield.co.uk (Richard Kirk)\\nSubj...\n",
      "1494  From: mcovingt@aisun3.ai.uga.edu (Michael Covi...\n",
      "1495  From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...\n",
      "1496  From: ac940@Freenet.carleton.ca (Lau Hon-Wah)\\...\n",
      "1497  From: andersom@spot.Colorado.EDU (Marc Anderso...\n",
      "1498  From: bj368@cleveland.Freenet.Edu (Mike E. Rom...\n",
      "1499  From: Donald Mackie <Donald_Mackie@med.umich.e...\n",
      "1500  From: abruno@adobe (Andrea Bruno)\\nSubject: Re...\n",
      "1501  From: matt-dah@dsv.su.se (Mattias Dahlberg)\\nS...\n",
      "\n",
      "[1502 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "df_stem_train = pd.DataFrame.from_records(X_train, columns = ['text'])\n",
    "print(df_stem_train.info)\n",
    "X_stem_train = df_stem_train['text'].map(lambda text: stemmer.stem(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_stem_test = pd.DataFrame.from_records(X_test, columns = ['text'])\n",
    "print(df_stem_test.info)\n",
    "X_stem_test = df_stem_test['text'].map(lambda text: stemmer.stem(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## b) Text Preprocessing & c) Feature Vectorization\n",
    "\n",
    "We can combine text preprocessing, feature vectorization and model training using the sklearn Pipeline object. This Pipeline object can be used for model selection and for training the optimal model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> 3. Model Selection </font>\n",
    "\n",
    "\n",
    "There are no hyperparameters in a NB model except the Laplace smoothing parameter alpha.\n",
    "\n",
    "However, there are multiple hyperparameters for the CountVectorizer() and TfidfTransformer(). We need to select the best model based on the optimal values of these hyperparameters. This process is called hyper-parameter tuning.\n",
    "\n",
    "For hyperparameter tuning, we will build a compund classifier using the sklearn Pipeline class. It will combine the CountVectorizer(), TfidfTransformer() and MultinomialNB() objects and will create a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline for Hyperparameter Tuning\n",
    "\n",
    "\n",
    "#### Task 4: Build a Pipeline object by combining CountVectorizer() and MultinomialNB() (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "#### Task 5: Perform hyperparamer tuning for the following hyperparameters: (5 pts)\n",
    "- CountVectorizer()\n",
    "         -- ngram_range\n",
    "         -- stop_words\n",
    "- MultinomialNB()\n",
    "        -- alpha\n",
    "        \n",
    "## **<font color=red size=5>Important:</font>**\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For multiclass classification, we may use \"f1_micro\" scoring function. The f1_micro function is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "The macro-average (\"f1_macro\") will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average (\"f1_micro\") will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\n",
    "\n",
    "In the binary classification, \"f1\" score function can be used. We may also use the precision_score, recall_score, roc_auc_score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score lemmatized model: 0.980948\n",
      "\n",
      "Optimal lemmatized model Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "\n",
      "Best Score stemming model: 0.980948\n",
      "\n",
      "Optimal stemming model Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "#     'vect__binary': [True, False],\n",
    "    'clf__alpha': [0.1, 1.0, 1.5, 1.8],\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "}\n",
    "\n",
    "clf_lem_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1_micro', cv=5)\n",
    "\n",
    "clf_lem_multinomial_cv = clf_lem_multinomial_cv.fit(X_lem_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBest Score lemmatized model: %f\" % clf_lem_multinomial_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal lemmatized model Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, clf_lem_multinomial_cv.best_params_[param_name]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stemming\n",
    "clf_stem_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1_micro', cv=5)\n",
    "\n",
    "clf_stem_multinomial_cv = clf_stem_multinomial_cv.fit(X_stem_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest Score stemming model: %f\" % clf_stem_multinomial_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal stemming model Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, clf_stem_multinomial_cv.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 4. Train the Optimal Multinomial Model </font>\n",
    "\n",
    "#### Task 6: Using the optimal hyperparameter values, create the optimal model. Then, fit the model. (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_lem_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_lem_clf.fit(X_lem_train, y_train)\n",
    "\n",
    "\n",
    "#stemming\n",
    "multinomialNB_stem_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_stem_clf.fit(X_stem_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 6. Evaluate the Model on Test Data </font>\n",
    "\n",
    "#### Task 7:  Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report\n",
    "\n",
    "\n",
    "### Note: For multi-class classification, set the \"average\" attribute to \"micro\" for the following functions:\n",
    "- precision_score\n",
    "- recall_score\n",
    "- f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Model\n",
      "\n",
      "Test Confusion Matrix :\n",
      "[[299   4   5  11]\n",
      " [  5 371  11   2]\n",
      " [  7  18 362   9]\n",
      " [  4   3   6 385]]\n",
      "\n",
      "Test Precision = 0.943409\n",
      "Test Recall = 0.943409\n",
      "Test F1 Score = 0.943409\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.94      0.94       319\n",
      "soc.religion.christian       0.94      0.95      0.95       389\n",
      "         comp.graphics       0.94      0.91      0.93       396\n",
      "               sci.med       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n",
      "Stemming model\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[299   4   5  11]\n",
      " [  5 371  11   2]\n",
      " [  7  18 362   9]\n",
      " [  4   3   6 385]]\n",
      "\n",
      "Test Precision = 0.943409\n",
      "Test Recall = 0.943409\n",
      "Test F1 Score = 0.943409\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.94      0.94       319\n",
      "soc.religion.christian       0.94      0.95      0.95       389\n",
      "         comp.graphics       0.94      0.91      0.93       396\n",
      "               sci.med       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_predicted = multinomialNB_lem_clf.predict(X_lem_test)\n",
    "\n",
    "print(\"Lemmatized Model\")\n",
    "print(\"\\nTest Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted,average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted,  average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))\n",
    "\n",
    "\n",
    "\n",
    "#stemming\n",
    "y_test_predicted = multinomialNB_stem_clf.predict(X_stem_test)\n",
    "\n",
    "print(\"Stemming model\")\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted,average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted,  average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multinomial NB: TF-IDF Model\n",
    "\n",
    "#### Task 8: Implement the Multinomial model using the TF-IDF feature vectors (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer(), TfidfTransformer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf_tfidf_lem = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 1), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_clf_tfidf_lem.fit(X_lem_train, y_train)\n",
    "\n",
    "\n",
    "multinomialNB_clf_tfidf_stem = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 1), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf_tfidf_stem.fit(X_stem_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "#### Task 9: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized model\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[273   3   7  36]\n",
      " [  3 377   2   7]\n",
      " [  3  17 359  17]\n",
      " [  3   3   3 389]]\n",
      "\n",
      "Test Precision = 0.930759\n",
      "Test Recall = 0.930759\n",
      "Test F1 Score = 0.930759\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.86      0.91       319\n",
      "soc.religion.christian       0.94      0.97      0.96       389\n",
      "         comp.graphics       0.97      0.91      0.94       396\n",
      "               sci.med       0.87      0.98      0.92       398\n",
      "\n",
      "             micro avg       0.93      0.93      0.93      1502\n",
      "             macro avg       0.94      0.93      0.93      1502\n",
      "          weighted avg       0.93      0.93      0.93      1502\n",
      "\n",
      "Stemming model\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[273   3   7  36]\n",
      " [  3 377   2   7]\n",
      " [  3  17 359  17]\n",
      " [  3   3   3 389]]\n",
      "\n",
      "Test Precision = 0.930759\n",
      "Test Recall = 0.930759\n",
      "Test F1 Score = 0.930759\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.86      0.91       319\n",
      "soc.religion.christian       0.94      0.97      0.96       389\n",
      "         comp.graphics       0.97      0.91      0.94       396\n",
      "               sci.med       0.87      0.98      0.92       398\n",
      "\n",
      "             micro avg       0.93      0.93      0.93      1502\n",
      "             macro avg       0.94      0.93      0.93      1502\n",
      "          weighted avg       0.93      0.93      0.93      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_predicted = multinomialNB_clf_tfidf_lem.predict(X_lem_test)\n",
    "\n",
    "print(\"Lemmatized model\")\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))\n",
    "\n",
    "\n",
    "y_test_predicted = multinomialNB_clf_tfidf_stem.predict(X_stem_test)\n",
    "\n",
    "print(\"Stemming model\")\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multinomial Model With TF-IDF Feature Vectors </font>\n",
    "\n",
    "We observe that both precision and recall decrease with TF-IDF feature vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Bernoulli NB\n",
    "\n",
    "#### Task 10: Implement the Multivariate Bernoulli Model (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and BernoulliNB()\n",
    "\n",
    "### <font color=red> Note: </font>\n",
    "The \"binary\" attribute of the CountVectorizer() object should be set to \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulliNB_clf_lem = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=True)),\n",
    "        ('clf', BernoulliNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "bernoulliNB_clf_lem.fit(X_lem_train, y_train)\n",
    "\n",
    "\n",
    "bernoulliNB_clf_stem = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=True)),\n",
    "        ('clf', BernoulliNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "bernoulliNB_clf_stem.fit(X_stem_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "\n",
    "#### Task 11: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Model\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[288  18   5   8]\n",
      " [  2 385   2   0]\n",
      " [  3 107 284   2]\n",
      " [  3  36   1 358]]\n",
      "\n",
      "Test Precision = 0.875499\n",
      "Test Recall = 0.875499\n",
      "Test F1 Score = 0.875499\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.90      0.94       319\n",
      "soc.religion.christian       0.71      0.99      0.82       389\n",
      "         comp.graphics       0.97      0.72      0.83       396\n",
      "               sci.med       0.97      0.90      0.93       398\n",
      "\n",
      "             micro avg       0.88      0.88      0.88      1502\n",
      "             macro avg       0.91      0.88      0.88      1502\n",
      "          weighted avg       0.90      0.88      0.88      1502\n",
      "\n",
      "Stemming model\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[288  18   5   8]\n",
      " [  2 385   2   0]\n",
      " [  3 107 284   2]\n",
      " [  3  36   1 358]]\n",
      "\n",
      "Test Precision = 0.875499\n",
      "Test Recall = 0.875499\n",
      "Test F1 Score = 0.875499\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.90      0.94       319\n",
      "soc.religion.christian       0.71      0.99      0.82       389\n",
      "         comp.graphics       0.97      0.72      0.83       396\n",
      "               sci.med       0.97      0.90      0.93       398\n",
      "\n",
      "             micro avg       0.88      0.88      0.88      1502\n",
      "             macro avg       0.91      0.88      0.88      1502\n",
      "          weighted avg       0.90      0.88      0.88      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_test_predicted_lem = bernoulliNB_clf_lem.predict(X_lem_test)\n",
    "\n",
    "print(\"Lemmatized Model\")\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted_lem))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted_lem, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted_lem, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted_lem, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted_lem, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_predicted = bernoulliNB_clf_stem.predict(X_stem_test)\n",
    "\n",
    "print(\"Stemming model\")\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multivariate Bernoulli Model </font>\n",
    "\n",
    "#### Task 12: Write a short account of your observation on the following aspects of your experimentation with 3 NB classifiers (10 pts):\n",
    "- Impact of data normalization technique (did you observe performance improvement with lemmatization and/or stemming)\n",
    "\n",
    "##### Answer - I did stemming and lemmatization but surprisingly I am getting the same results for both.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Which classifier gave the best precision? Best recall? Best F1 Score? Explain their performance variance.\n",
    "\n",
    "##### Answer: \n",
    "Multinomial NB gave the best Precision = 0.943409,\n",
    "Test Recall = 0.943409,\n",
    "Test F1 Score = 0.943409 as compared to other models.\n",
    "\n",
    "Whereas the Multinomial NB: TF-IDF Model gave slightly less scores with Test Precision = 0.930759,\n",
    "Test Recall = 0.930759,\n",
    "Test F1 Score = 0.930759.\n",
    "\n",
    "But the Multivariate Bernoulli NB gave the worst scores of all the three with Test Precision = 0.875499,\n",
    "Test Recall = 0.875499,\n",
    "Test F1 Score = 0.875499.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
