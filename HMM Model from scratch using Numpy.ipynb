{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI:  [ 0.5  0.5]\n",
      "A:  [[ 0.999  0.001]\n",
      " [ 0.2    0.8  ]]\n",
      "B:  [[ 0.05  0.35  0.2   0.2   0.2 ]\n",
      " [ 0.5   0.1   0.3   0.1   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PI=np.array([0.5,0.5])\n",
    "A=np.array([[0.999,0.001],[0.2,0.8]])\n",
    "B=np.array([[0.05,0.35,0.20,0.20,0.20],[0.5,0.1,0.3,0.1,0.0]])\n",
    "\n",
    "print(\"PI: \",PI)\n",
    "print(\"A: \",A)\n",
    "print(\"B: \",B)\n",
    "obs_map = {0:'Movement'\n",
    "            , 1:'Passive Social Networking'\n",
    "            , 2:'Active Social Networking'\n",
    "            , 3:'Texting'\n",
    "            , 4:'Access Psych Health App/Sites'}\n",
    "Observables=np.array([0,3,0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha unnormalized:  [[ 0.025       0.014995    0.00094903  0.00050996]\n",
      " [ 0.25        0.0200025   0.0080085   0.00064077]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def forward(PI,A,B,Observables): \n",
    "    alpha=np.zeros(shape=(len(PI),len(Observables)))    \n",
    "    alpha[:,0]=PI*B[:,Observables[0]]\n",
    "    for i in range(0,len(Observables)-1):      \n",
    "        alpha[:,i+1]= (np.matmul(alpha[:,i],A))* (B[:,Observables[i+1]])\n",
    "    return alpha\n",
    "alpha=forward(PI,A,B,Observables)\n",
    "print(\"Alpha unnormalized: \",alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha normalized: [[ 0.09090909  0.42845918  0.10594729  0.44315801]\n",
      " [ 0.90909091  0.57154082  0.89405271  0.55684199]]\n",
      "C: [ 3.63636364  7.85770412  3.9070512   7.78420997]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def forward_normalized(PI,A,B,Observables):\n",
    "    c = np.zeros(shape=(len(Observables),))\n",
    "    alpha = forward(PI,A,B,Observables)\n",
    "    alpha_normalized = np.zeros(shape=(len(PI),len(Observables)))\n",
    "    c[0] = 1/(sum(alpha[:,0]))\n",
    "    alpha_normalized[:,0] = alpha[:,0]*c[0]\n",
    "    \n",
    "    # alpha notmalized the way its done in recitation\n",
    "    for i in range(0,len(alpha[0])-1):\n",
    "        alpha_normalized[:,i+1]= (np.matmul(alpha_normalized[:,i],A))* (B[:,Observables[i+1]])\n",
    "        c[i+1] = 1/(sum(alpha_normalized[:,i+1]))\n",
    "        alpha_normalized[:,i+1]=alpha_normalized[:,i+1]*c[i+1]\n",
    "    return alpha_normalized,c\n",
    "\n",
    "a,c = (forward_normalized(PI,A,B,Observables))\n",
    "print(\"Alpha normalized:\",a)\n",
    "print(\"C:\",c)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation un-normalized:  0.320105752597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluation_unnormalized(alpha):\n",
    "    return(np.sum(alpha))\n",
    "print(\"Evaluation un-normalized: \",evaluation_unnormalized(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation normalized:  -6.76735888793\n"
     ]
    }
   ],
   "source": [
    "def evaluation_normalized(c):\n",
    "    total = 0.0\n",
    "    for i in range(len(c)):\n",
    "        total = total + np.log(c[i]) # used natural log to compute the log probablity\n",
    "    return (-total)\n",
    "print(\"Evaluation normalized: \",evaluation_normalized(c))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta un-normalized:  [[ 0.00201598  0.01008495  0.1999      1.        ]\n",
      " [ 0.005904    0.0492      0.12        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def backward(PI,A,B,Observables): \n",
    "    beta=np.zeros(shape=(len(PI),len(Observables)))\n",
    "    beta[:,len(Observables)-1]=1 \n",
    "    for j in range(len(Observables)-2,-1,-1):\n",
    "        beta[:,j]=(np.matmul(A,B[:,Observables[j+1]]))* beta[:,j+1]\n",
    "    return beta\n",
    "beta=backward(PI,A,B,Observables)\n",
    "print(\"Beta un-normalized: \",beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta normalized:  [[  7.33084547e-03   7.92445925e-02   7.81019535e-01   7.78420997e+00]\n",
      " [  2.14690909e-02   3.86599043e-01   4.68846144e-01   7.78420997e+00]]\n"
     ]
    }
   ],
   "source": [
    "def backward_normalized(PI,A,B,c,Observables):\n",
    "    beta=backward(PI,A,B,Observables)\n",
    "    beta_normalized = np.zeros(shape=(len(PI),len(Observables)))\n",
    "    for i in range(0,len(Observables)):\n",
    "        beta_normalized[:,i] = beta[:,i]*c[i]\n",
    "    return beta_normalized\n",
    "print(\"Beta normalized: \",backward_normalized(PI,A,B,c,Observables))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing by Forward-Backward Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed Probability matrix:  [[ 0.03301859  0.13319621  0.16486072  0.44315801]\n",
      " [ 0.96698141  0.86680379  0.83513928  0.55684199]]\n"
     ]
    }
   ],
   "source": [
    "def smoothed_probability(alpha,beta,noStates, noOfTimeSteps):\n",
    "    smoothed_matrix=np.zeros(shape=(noStates,noOfTimeSteps))\n",
    "    for j in range(noOfTimeSteps):\n",
    "        smoothed_matrix[:,j]=(alpha[:,j]*beta[:,j])/np.dot(alpha[:,j],beta[:,j])        \n",
    "    return smoothed_matrix\n",
    "\n",
    "print(\"Smoothed Probability matrix: \",smoothed_probability(alpha,beta,len(PI), len(Observables)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
