{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-m4It3XszpU"
   },
   "source": [
    "## Linear Regression - Ordinary Least Squares (OLS) Method \n",
    "\n",
    "We will perform linear regression using\n",
    "- Scikit Learn's OLS model\n",
    "- Manually coded OLS method\n",
    "\n",
    "\n",
    "The sklearn OLS implementation code is given in this notebook. You will have to implement the OLS method manually on the given dataset (OLS_Data.csv).\n",
    "\n",
    "\n",
    "### OLS\n",
    "\n",
    "OLS is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function.\n",
    "\n",
    "OLS finds the optimal parameters by computing a closed-form solution for the **Normal equation**.\n",
    "\n",
    "URL: https://scikit-learn.org/stable/modules/linear_model.html#linear-model\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We will use a dataset (OLS_Data.csv) containing 14 variables (14 dimensional feature)\n",
    "\n",
    "Input variables:\n",
    "X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14\n",
    "\n",
    "Output variable: \n",
    "y\n",
    "\n",
    "### Note:\n",
    "This dataset might have colinearity in the input variables resulting into the singularity problem. It might cause the OLS method not working. You may need to fix the singularity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-VJAFEjszpW"
   },
   "source": [
    "# Part 1: OLS Linear Regression Using Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoykro6-szpW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36NGvqGWszpZ"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "First load the data and explore the feature names, target names, etc.\n",
    "\n",
    "Download the \"OLS_Data.csv\" file to load data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5klF0wFYszpa",
    "outputId": "1b92bf3f-f331-4f60-e67e-269b9a909dbd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# load the csv file as a Pandas DataFrame object denoted as \"df\"\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import pandas as pd\n",
    "df= pd.read_csv('/content/drive/My Drive/Colab Notebooks/OLS_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fdxs09Dmszpc"
   },
   "source": [
    "# Quick Check of the Data\n",
    "\n",
    "Let’s take a look at the top five rows using the DataFrame’s head() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KwkCk5ELszpd",
    "outputId": "7151826a-effe-4645-92c9-29d73d4e2853"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1    X2    X3  X4     X5     X6    X7      X8  X9  X10   X11     X12  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296  15.3  396.90   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242  17.8  396.90   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242  17.8  392.83   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222  18.7  394.63   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222  18.7  396.90   \n",
       "\n",
       "    X13      X14     y  \n",
       "0  4.98  0.00632  24.0  \n",
       "1  9.14  0.02731  21.6  \n",
       "2  4.03  0.02729  34.7  \n",
       "3  2.94  0.03237  33.4  \n",
       "4  5.33  0.06905  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDduIjYCszpf"
   },
   "source": [
    "# Description of the Data\n",
    "\n",
    "DataFrame’s info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "NV9jfWejszpf",
    "outputId": "4de6f0b0-3cbb-4a0c-9c3a-1b70ad19768e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 15 columns):\n",
      "X1     506 non-null float64\n",
      "X2     506 non-null float64\n",
      "X3     506 non-null float64\n",
      "X4     506 non-null int64\n",
      "X5     506 non-null float64\n",
      "X6     506 non-null float64\n",
      "X7     506 non-null float64\n",
      "X8     506 non-null float64\n",
      "X9     506 non-null int64\n",
      "X10    506 non-null int64\n",
      "X11    506 non-null float64\n",
      "X12    506 non-null float64\n",
      "X13    506 non-null float64\n",
      "X14    506 non-null float64\n",
      "y      506 non-null float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 59.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJlh1KUKszph"
   },
   "source": [
    "## Data Matrix: Feature Correlations\n",
    "\n",
    "Check if the data matrix has colinearity (1 or close to 1) in its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "JrJCqhioszpi",
    "outputId": "bd169b92-2019-4c71-e55e-ff81bde16ed6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>-0.388305</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "X1   1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "X2  -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "X3   0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "X4  -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "X5   0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "X6  -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "X7   0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "X8  -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "X9   0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "X10  0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "X11  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "X12 -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "X13  0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "X14  1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "y   -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "           X8        X9       X10       X11       X12       X13       X14  \\\n",
       "X1  -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  1.000000   \n",
       "X2   0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995 -0.200469   \n",
       "X3  -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  0.406583   \n",
       "X4  -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929 -0.055892   \n",
       "X5  -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  0.420972   \n",
       "X6   0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808 -0.219247   \n",
       "X7  -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  0.352734   \n",
       "X8   1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996 -0.379670   \n",
       "X9  -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  0.625505   \n",
       "X10 -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  0.582764   \n",
       "X11 -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  0.289946   \n",
       "X12  0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087 -0.385064   \n",
       "X13 -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  0.455621   \n",
       "X14 -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  1.000000   \n",
       "y    0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663 -0.388305   \n",
       "\n",
       "            y  \n",
       "X1  -0.388305  \n",
       "X2   0.360445  \n",
       "X3  -0.483725  \n",
       "X4   0.175260  \n",
       "X5  -0.427321  \n",
       "X6   0.695360  \n",
       "X7  -0.376955  \n",
       "X8   0.249929  \n",
       "X9  -0.381626  \n",
       "X10 -0.468536  \n",
       "X11 -0.507787  \n",
       "X12  0.333461  \n",
       "X13 -0.737663  \n",
       "X14 -0.388305  \n",
       "y    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vgcwThKgqFI"
   },
   "source": [
    "Features X1 and X14 has high correlation 1 between each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oinHfJZCszpk"
   },
   "source": [
    "# Create a Separate Feature Set (Data Matrix X) and Target (1D Vector y)\n",
    "\n",
    "Create a data matrix (X) that contains all features and a 1D target vector (y) containing the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HQAyPHe5szpl",
    "outputId": "c97f51d1-ec08-40ad-f5a7-c9c94ef0efe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "# data matrix X\n",
    "X = np.array(df.iloc[:,0:14])\n",
    "\n",
    "# target vector y\n",
    "y = np.array(df.iloc[:,14:])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9e3puPAkszpn"
   },
   "source": [
    "# Scale The Features\n",
    "\n",
    "We should ensure that all features have a similar scale. Otherwise optimization algorithms (e.g., Gradient Descent based algorithms) will take much longer time to converge.\n",
    "\n",
    "Also, regularization techniques are sensitive to the scale of data. Thus, we must scale the features before applying regularization.\n",
    "\n",
    "Use sklearns StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7StxwxRszpo"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WS_8Q0Rwszpr"
   },
   "source": [
    "# Create Train and Test Dataset\n",
    "\n",
    "Create train and test data (80% & 20%) by usinf sklearn's train_test_split function\n",
    "\n",
    "It should return the following 4 matrices.\n",
    "X_train\n",
    "y_train\n",
    "X_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fz9lBSsrszps"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbDL55HXszpu"
   },
   "source": [
    "## Linear Regression Models\n",
    "\n",
    "We will use the following linear regression models.\n",
    "\n",
    "- Ordinary least squares (OLS) Linear Regression (by solving the Normal Equation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wYoF9u_aszpv"
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We will use two evaluation metrics.\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Coefficient of Determination ($R^2$ or $r^2$)\n",
    "\n",
    "\n",
    "### Note on $R^2$:\n",
    "R-squared is a statistical measure of how close the data are to the fitted regression line. \n",
    "\n",
    "R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "$R^2 = \\frac{Explained Variation}{Total Variation}$\n",
    "\n",
    "R-squared is always between 0 and 100%:\n",
    "\n",
    "- 0% indicates that the model explains none of the variability of the response data around its mean.\n",
    "- 100% indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "\n",
    "#### <font color=red>In general, the higher the R-squared, the better the model fits your data.</font>\n",
    "\n",
    "\n",
    "#### Compute $R^2$ using the sklearn:\n",
    "\n",
    "- The \"r2_score\" function from sklearn.metrics\n",
    "\n",
    "#### Compute MSE using the sklearn:\n",
    "\n",
    "- The \"mean_squared_error\" function from sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iawo60v1szpv"
   },
   "source": [
    "## Sklearn Ordinary Least Squares (OLS) Linear Regression (by solving the Normal Equation)\n",
    "\n",
    "\n",
    "#### Sklearn's OLS model implementation code is given for you to review.\n",
    "\n",
    "Then, you will have to manually code the OLS method.\n",
    "\n",
    "\n",
    "#### <font color=red>The MSE and $r^2$ error values from your manually coded OLS method must match with sklearn LinearRegressor's obtained values.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ikCEHuSTszpw",
    "outputId": "625cd6cb-5eb0-426e-8544-5c0a0c8f3bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Intercept: \\n', array([22.48526824]))\n",
      "('Coefficients: \\n', array([[-0.48574711,  0.70155562,  0.27675212,  0.70653152, -1.99143043,\n",
      "         3.11571836, -0.17706021, -3.04577065,  2.28278471, -1.79260468,\n",
      "        -1.97995351,  1.12649864, -3.62814937, -0.48574711]]))\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 21.64\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.75\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Create the sklearn OLS linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# The intercept\n",
    "print(\"Intercept: \\n\", lin_reg.intercept_)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", lin_reg.coef_)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted = lin_reg.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "\n",
    "# To compute \n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % lin_reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzgCWuyvszpz"
   },
   "source": [
    "## Evaluate the Sklearn OLS Model Using Test Data \n",
    "\n",
    "We evaluate the trained model on the test data.\n",
    "\n",
    "The goal is to see how the model performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hWuUQ_SRszpz",
    "outputId": "a344ca73-0a34-4c3e-88c2-4789e104b9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 24.29\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Make prediction \n",
    "y_test_predicted = lin_reg.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mApvJsWszp2"
   },
   "source": [
    "## Manually Coded OLS Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "l5iOzftvszp3",
    "outputId": "aabdef1c-9c96-4e53-954e-f1fe3474530b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nDeterminant of (X_train_bias^T.X_train_bias): ', 0.0)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-21e4d90370e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Closed form (OLS) solution for weight vector w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nThe weight vector:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Manually code the OLS Method for Linear Regression\n",
    "\n",
    "\n",
    "# Add a bias term with the feature vectors to create a new data matrix \"X_train_bias\"\n",
    "X_train_bias=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
    "\n",
    "\n",
    "# Print the determinant of the dot product of the transpose of X_train_bias and X_train_bias\n",
    "print(\"\\nDeterminant of (X_train_bias^T.X_train_bias): \",det(X_train_bias.T.dot(X_train_bias)))\n",
    "\n",
    "\n",
    "# Computes the dot product of the transpose of X_train_bias with itself\n",
    "#  Denote the product as \"z\"\n",
    "\n",
    "z = X_train_bias.T.dot(X_train_bias)\n",
    "\n",
    "# Closed form (OLS) solution for weight vector w \n",
    "w = np.linalg.inv(z).dot(X_train_bias).T.dot(y)\n",
    "\n",
    "print(\"\\nThe weight vector:\\n\")\n",
    " \n",
    "print(w)\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Make prediction using the X_train_bias data matrix\n",
    "# The predicted target vector should be named as \"y_train_predicted\"\n",
    "y_train_predicted = X_train_bias.dot(w)\n",
    "\n",
    "# Compute the MSE\n",
    "print(\"Mean squared error:\", mean_squared_error(y, y_predicted))\n",
    "\n",
    "\n",
    "# Compute the r^2 score\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]:\", r2_score(y, y_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoKK77RIszp5"
   },
   "source": [
    "## Observation on the Performance of the Manually Coded OLS Solution\n",
    "\n",
    "You might get the **Singularity matrix** error.\n",
    "\n",
    "The determinant of the $X_{bias}^T.X_{bias}$ should be 0.\n",
    "\n",
    "There must be colinearity in the columns of the data matrix X.\n",
    "\n",
    "Find which columns are coliner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzM0_6PQszp8"
   },
   "source": [
    "## Applying OLS Method on Data Matrix With Colinearity in Columns\n",
    "\n",
    "Solve the singularity problem can by adding small positive numbers on the diagonal of the $X_{bias}^T.X_{bias}$ matrix.\n",
    "\n",
    "This regularization technique is known as **Ridge Regression**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "6TIK3qXNszp9",
    "outputId": "421466be-6b41-4461-8077-6bc62632f799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nDeterminant of (X_train_bias^T.X_train_bias): ', 0.0)\n",
      "\n",
      "-------- Fixing the Singularity of (X_bias^T).X_bias ------------\n",
      "\n",
      "The weight vector:\n",
      "\n",
      "[[22.48521177]\n",
      " [-0.48574245]\n",
      " [ 0.70153482]\n",
      " [ 0.27672332]\n",
      " [ 0.70653526]\n",
      " [-1.99139527]\n",
      " [ 3.115727  ]\n",
      " [-0.17706139]\n",
      " [-3.04573205]\n",
      " [ 2.28270084]\n",
      " [-1.7925275 ]\n",
      " [-1.97994666]\n",
      " [ 1.12649546]\n",
      " [-3.62813639]\n",
      " [-0.48574245]]\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "('Mean squared error:', 21.6414127578023)\n",
      "('Coefficient of determination r^2 variance score [1 is perfect prediction]:', 0.7508856358452931)\n"
     ]
    }
   ],
   "source": [
    "# Bayesian (Regularized) OLS Method for Linear Regression: Ridge Regression\n",
    "\n",
    "\n",
    "\n",
    "# Add a bias term with the feature vectors to create a new data matrix \"X_train_bias\"\n",
    "X_train_bias=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
    "\n",
    "\n",
    "# Print the determinant of the dot product of the transpose of X_train_bias and X_train_bias\n",
    "print(\"\\nDeterminant of (X_train_bias^T.X_train_bias): \", det(X_train_bias.T.dot(X_train_bias)))\n",
    "\n",
    "\n",
    "# Computes the dot product of the transpose of X_train_bias with itself\n",
    "#  Denote the product as \"z\"\n",
    "\n",
    "z = X_train_bias.T.dot(X_train_bias)\n",
    "\n",
    "\n",
    "print(\"\\n-------- Fixing the Singularity of (X_bias^T).X_bias ------------\")\n",
    "\n",
    "# Create a diagonal matrix that has the dimension of z; name the matrix as \"diagonal\"\n",
    "f = np.full((15,),0.001)\n",
    "diagonal = np.diagflat(f)\n",
    "\n",
    "# Add small positive non-zero numbers on the diagonal\n",
    "z = z + diagonal\n",
    "\n",
    "\n",
    "\n",
    "# Closed form (OLS) solution for weight vector w \n",
    "w = np.linalg.inv(z).dot(X_train_bias.T).dot(y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nThe weight vector:\\n\")\n",
    "print(w)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Make prediction using the X_train_bias data matrix\n",
    "# The predicted target vector should be named as \"y_train_predicted\"\n",
    "y_train_predicted = X_train_bias.dot(w)\n",
    "\n",
    "# Compute the MSE\n",
    "print(\"Mean squared error:\", mean_squared_error(y_train, y_train_predicted))\n",
    "\n",
    "\n",
    "# Compute the r^2 score\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]:\", r2_score(y_train, y_train_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEEcE8P2szp_"
   },
   "source": [
    "## Evaluate the Model Using Test Data - OLS Linear Regression\n",
    "\n",
    "We evaluate the trained model on the test data.\n",
    "\n",
    "Compute the MSE and $r^2$ score using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "v9kmjVF_szqA",
    "outputId": "c30e78d9-a2e0-43d5-b32c-87ecd30259e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean squared error:', 24.291172758136184)\n",
      "('Coefficient of determination r^2 variance score [1 is perfect prediction]:', 0.668758766951507)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
    "\n",
    "# Make prediction using the X_train_bias data matrix\n",
    "# The predicted target vector should be named as \"y_train_predicted\"\n",
    "y_test_predicted = X_test.dot(w)\n",
    "\n",
    "# Compute the MSE\n",
    "print(\"Mean squared error:\", mean_squared_error(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "# Compute the r^2 score\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]:\", r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mAoWRTQdszqF"
   },
   "source": [
    "# Part 2: Understanding the Singularity Issue and its Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovDFjZ7GszqH"
   },
   "source": [
    "1) Why do you think the singularity matrix error occur while using OLS method on the “OLS_Data.csv” dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBvPfo9IszqI"
   },
   "source": [
    "Answer: The singularity error occured because the determinant was zero. We had colinearity in the dataset. The features X1 and X14 are having correlation of 1. Due to which the matrix was not full rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1GHC_cgszqJ"
   },
   "source": [
    "2) To fix the singularity problem of the $X_{bias}^T.X_{bias}$ matrix what non-zero positive number did you add on its diagonal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vwhusXQszqK"
   },
   "source": [
    "Answer: I added 0.001 to the diagonal of my matrix. 𝑋𝑇𝑏𝑖𝑎𝑠.𝑋𝑏𝑖𝑎𝑠 was denoted by 'z' in my code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBrZVmm6szqL"
   },
   "source": [
    "3) Add 100000 on the diagonal of the $X_{bias}^T.X_{bias}$ matrix and report the $MSE$ and the $r^2$ values for the training data set. Explain these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxHEYVCxszqM"
   },
   "source": [
    "Answer: MSE for it 581.2107484879942 and  $r^2$  -5.745386629250396. We cannot have very high penalty/regularization because adding too high penality would be equal to adding noise in the data. Hence, we have very high MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bsXyq08szqM"
   },
   "source": [
    "4) After adding 100000 on the diagonal of the $X_{bias}^T.X_{bias}$ matrix what change did you notice in the weights of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wvqeppvszqN"
   },
   "source": [
    "Answer: The positive weights have decreased and the negative weights have increased."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Maan_Sumeet_8",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
